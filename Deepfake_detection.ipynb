{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YNwgosglqBiN"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AiXZ9ebxqEJA"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess video files into frames\n",
    "def preprocess_video(video_path, num_frames=30, frame_height=128, frame_width=128):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "    for _ in range(num_frames):\n",
    "        frame_index = np.random.randint(0, frame_count)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (frame_height, frame_width))\n",
    "            frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "B4FMU8apqGiI"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess all videos in your dataset\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gT1gjOicqIco"
   },
   "outputs": [],
   "source": [
    "fake_video_dir = r'C:\\Users\\Master\\Documents\\Deepfake Detection\\fake'\n",
    "real_video_dir = r'C:\\Users\\Master\\Documents\\Deepfake Detection\\real'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EksW1RU3wxlY"
   },
   "outputs": [],
   "source": [
    "# Process fake videos\n",
    "for video_file in os.listdir(fake_video_dir):\n",
    "    video_path = os.path.join(fake_video_dir, video_file)\n",
    "    frames = preprocess_video(video_path)\n",
    "    X.append(frames)\n",
    "    y.append(1)  # Label 1 for fake videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aqde_lvmw0P5"
   },
   "outputs": [],
   "source": [
    "# Process real videos\n",
    "for video_file in os.listdir(real_video_dir):\n",
    "    video_path = os.path.join(real_video_dir, video_file)\n",
    "    frames = preprocess_video(video_path)\n",
    "    X.append(frames)\n",
    "    y.append(0)  # Label 0 for real videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h6jIbhsUw2kj"
   },
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mzwrgqgVqcFS"
   },
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "model = Sequential([\n",
    "    Conv3D(32, (3, 3, 3), activation='relu', input_shape=(30, 128, 128, 3)),\n",
    "    MaxPooling3D((2, 2, 2)),\n",
    "    Conv3D(64, (3, 3, 3), activation='relu'),\n",
    "    MaxPooling3D((2, 2, 2)),\n",
    "    Conv3D(128, (3, 3, 3), activation='relu'),\n",
    "    MaxPooling3D((2, 2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2_Kppcgfqh-x"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "46pGeempqkcg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 12s/step - accuracy: 0.4285 - loss: 107.4855 - val_accuracy: 0.4250 - val_loss: 0.7241\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 8s/step - accuracy: 0.4786 - loss: 0.7261 - val_accuracy: 0.4750 - val_loss: 0.6882\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6s/step - accuracy: 0.5436 - loss: 0.6773 - val_accuracy: 0.4750 - val_loss: 0.6786\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 8s/step - accuracy: 0.6135 - loss: 0.6934 - val_accuracy: 0.4000 - val_loss: 0.6997\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6s/step - accuracy: 0.6605 - loss: 0.6326 - val_accuracy: 0.3750 - val_loss: 0.7148\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.6666 - loss: 0.6148 - val_accuracy: 0.4500 - val_loss: 0.7081\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6s/step - accuracy: 0.6827 - loss: 0.5644 - val_accuracy: 0.3750 - val_loss: 0.7229\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.6776 - loss: 0.5582 - val_accuracy: 0.4500 - val_loss: 0.7171\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7s/step - accuracy: 0.7305 - loss: 0.5265 - val_accuracy: 0.5000 - val_loss: 0.7277\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 5s/step - accuracy: 0.7423 - loss: 0.5146 - val_accuracy: 0.5000 - val_loss: 0.7188\n"
     ]
    }
   ],
   "source": [
    "# Train your CNN (assuming you have already defined your model)\n",
    "NUM_EPOCHS = 10\n",
    "history = model.fit(X_train, y_train, epochs=NUM_EPOCHS, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Az_TSj3cqmWR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - accuracy: 0.4354 - loss: 0.9374\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pn9Fvpw5qoan"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('deepfake_detection_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a video is fake or real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "The video is Fake\n"
     ]
    }
   ],
   "source": [
    "# Input a test video and preprocess\n",
    "test_frames=[]\n",
    "video_frames = preprocess_video('testv1.mp4')\n",
    "test_frames.append(video_frames)\n",
    "test_frames = np.array(test_frames)\n",
    "Deepfakedetection = load_model('deepfake_detection_model.h5')\n",
    "predictions=Deepfakedetection.predict(test_frames)\n",
    "# Funcion for post processing the predictions\n",
    "def postprocess_predictions(predictions):\n",
    "    processed_predictions = (predictions > 0.5).astype(int)\n",
    "    return processed_predictions\n",
    "# Final predictions\n",
    "processed_predictions = postprocess_predictions(predictions)\n",
    "if processed_predictions==1:\n",
    "    print(\"The video is Real\")\n",
    "else:\n",
    "    print(\"The video is Fake\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_deepfake():\n",
    "    video_path = filedialog.askopenfilename()\n",
    "    test_frames=[]\n",
    "    video_frames = preprocess_video(video_path)\n",
    "    test_frames.append(video_frames)\n",
    "    test_frames = np.array(test_frames)\n",
    "    Deepfakedetection = load_model('deepfake_detection_model.h5')\n",
    "    predictions=Deepfakedetection.predict(test_frames)\n",
    "    processed_predictions = (predictions > 0.5).astype(int)\n",
    "    result_label.config(text=\"The video is Real\" if np.all(processed_predictions == 1) else \"The video is Fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Tkinter GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Deep Fake Detection\")\n",
    "# Create a label for displaying the result\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Create a button to upload the video\n",
    "upload_button = tk.Button(root, text=\"Upload Video\", command=find_deepfake)\n",
    "upload_button.pack(pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_deepfake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m upload_frame\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Create a button to upload the video\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m upload_button \u001b[38;5;241m=\u001b[39m ttk\u001b[38;5;241m.\u001b[39mButton(upload_frame, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload Video\u001b[39m\u001b[38;5;124m\"\u001b[39m, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTButton\u001b[39m\u001b[38;5;124m'\u001b[39m, command\u001b[38;5;241m=\u001b[39mfind_deepfake)\n\u001b[0;32m     26\u001b[0m upload_button\u001b[38;5;241m.\u001b[39mpack(side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, padx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Create a label to display the result\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'find_deepfake' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Deep Fake Detection\")\n",
    "root.geometry(\"800x600\")  # Set the size of the root window\n",
    "\n",
    "# Define styles\n",
    "style = ttk.Style()\n",
    "style.configure('TButton', padding=10, font=('Helvetica', 14))\n",
    "style.configure('TLabel', padding=10, font=('Helvetica', 14))\n",
    "style.configure('TFrame', padding=10)\n",
    "\n",
    "# Create a frame for the header\n",
    "header_frame = ttk.Frame(root)\n",
    "header_frame.pack(pady=20)\n",
    "\n",
    "# Create a label for the header\n",
    "header_label = ttk.Label(header_frame, text=\"Deep Fake Detection\", style='TLabel')\n",
    "header_label.pack()\n",
    "\n",
    "# Create a frame for the video upload section\n",
    "upload_frame = ttk.Frame(root)\n",
    "upload_frame.pack(pady=20)\n",
    "\n",
    "# Create a button to upload the video\n",
    "upload_button = ttk.Button(upload_frame, text=\"Upload Video\", style='TButton', command=find_deepfake)\n",
    "upload_button.pack(side='left', padx=10)\n",
    "\n",
    "# Create a label to display the result\n",
    "result_label = ttk.Label(upload_frame, text=\"\", style='TLabel')\n",
    "result_label.pack(side='left')\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Master\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Master\\AppData\\Local\\Temp\\ipykernel_14976\\1134888224.py\", line 29, in check_video\n",
      "    predictions=Deepfakedetection.predict(video_frames)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Master\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Master\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 280, in _adjust_input_rank\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInvalid input shape for input Tensor(\"sequential_1_1/Cast:0\", shape=(32, 128, 128, 3), dtype=float32). Expected shape (None, 30, 128, 128, 3), but input has incompatible shape (32, 128, 128, 3)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(32, 128, 128, 3), dtype=uint8)\n",
      "  • training=False\n",
      "  • mask=None\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Function to preprocess the video frames\n",
    "def preprocess_video(video_path):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (128, 128))  # Resize the frame\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# Function to check if the video is real or fake\n",
    "def check_video():\n",
    "    global video_frames\n",
    "    \n",
    "    # Make predictions using the model\n",
    "    Deepfakedetection = load_model('deepfake_detection_model.h5')\n",
    "    predictions=Deepfakedetection.predict(video_frames)\n",
    "    \n",
    "    # Post-process the predictions\n",
    "    processed_predictions = postprocess_predictions(predictions)\n",
    "    \n",
    "    # Display the result\n",
    "    result_label.config(text=\"The uploaded video is Real\" if np.all(processed_predictions == 1) else \"The uploaded video is Fake\")\n",
    "\n",
    "# Function to handle video upload\n",
    "def upload_video():\n",
    "    global video_frames\n",
    "    \n",
    "    # Get the selected video file\n",
    "    video_path = filedialog.askopenfilename()\n",
    "   \n",
    "    # Preprocess the video frames\n",
    "    video_frames = preprocess_video(video_path)\n",
    "    \n",
    "    # Display the first frame of the video\n",
    "    if len(video_frames) > 0:\n",
    "        frame_image = Image.fromarray(video_frames[0])\n",
    "        frame_image.thumbnail((300, 300))  # Resize the image\n",
    "        frame_photo = ImageTk.PhotoImage(image=frame_image)\n",
    "        video_label.config(image=frame_photo)\n",
    "        video_label.image = frame_photo\n",
    "\n",
    "\n",
    "\n",
    "# Define the Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Deep Fake Detection\")\n",
    "root.geometry(\"800x600\")  # Set the size of the root window\n",
    "root.configure(bg=\"green\") \n",
    "\n",
    "# Define styles\n",
    "style = ttk.Style()\n",
    "style.configure('TButton', padding=10, font=('Helvetica', 14),background='lightgray')\n",
    "style.configure('TLabel', padding=10, font=('Times New Roman', 25,'bold'),background='green')\n",
    "style.configure('TFrame', padding=10,background='green')\n",
    "\n",
    "# Create a frame for the header\n",
    "header_frame = ttk.Frame(root)\n",
    "header_frame.pack(pady=20)\n",
    "\n",
    "# Create a label for the header\n",
    "header_label = ttk.Label(header_frame, text=\"DEEPFAKE CATCHER\", style='TLabel',foreground='white')\n",
    "header_label.pack()\n",
    "\n",
    "# Create a frame for the video display\n",
    "video_frame = ttk.Frame(root)\n",
    "video_frame.pack(pady=20)\n",
    "\n",
    "# Create a label to display the uploaded video\n",
    "video_label = ttk.Label(video_frame, style='TLabel')\n",
    "video_label.pack()\n",
    "\n",
    "# Create a frame for the video upload section\n",
    "upload_frame = ttk.Frame(root)\n",
    "upload_frame.pack(pady=20)\n",
    "\n",
    "# Create a button to upload the video\n",
    "upload_button = ttk.Button(upload_frame, text=\"Upload Video\", style='TButton', command=upload_video)\n",
    "upload_button.pack(side='left', padx=20)\n",
    "\n",
    "# Create a button to check the video\n",
    "check_button = ttk.Button(upload_frame, text=\"Check Video\", style='TButton', command=check_video)\n",
    "check_button.pack(side='left', padx=20)\n",
    "\n",
    "\n",
    "# Create a frame for the result label\n",
    "result_frame = ttk.Frame(root)\n",
    "result_frame.pack(pady=20)\n",
    "\n",
    "# Create a label to display the result\n",
    "result_label = ttk.Label(result_frame, text=\"\", style='TLabel',foreground='lightgray')\n",
    "result_label.pack()\n",
    "\n",
    "# Initialize variable to store video frames\n",
    "video_frames = []\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 128, 128, 3)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_frames[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
